# Deep Learning: Variational Autoencoders
In the previous post about autoencoders, we looked at their ability to compress data into a latent space and then reconstruct it with remarkable fidelity. Now, let's go a step further and create a generative model using the Variational Autoencoder (VAE). VAEs not only learn efficient data representations, but also allow us to generate new data by sampling from the learned latent space.

Variational Autoencoders take their name from *variational inference*, a powerful technique for approximating intractable probability distributions. The core idea of variational inference is to define a family of simpler, tractable distributions, and then use optimization to choose the best approximation within that family. VAE's connection to autoencoders isn't as direct, but will become clearer as we work through how a VAE learns a probabilistic endcoder and decoder.

# An Inference Problem

A variational autoencoder assumes that the observed data $X$ is generated from some latent variables $Z$ through a generative process. This process can be expressed as

$$ p(X,Z) = p(X|Z)p(Z) $$

In an image processing application for facial images, $X$ could be a high-resolution photo of a person's face, while $Z$ might be a lower-dimensional vector representing the latent features of the face, such as facial structure, expression, and skin tone. 

Given an observation $X$, the Bayesian inference problem is to find the posterior distribution $p(Z \| X)$. 

$$ p(Z|X) = \frac{p(X|Z)p(Z)}{p(X)} $$

Unfortunately, the marginal probability $p(X)$ may be unavailable or may require exponential time to integrate over all the latent variables,

$$ p(X) = \int p(X|z)p(z) dz $$

Instead of computing the intractable $p(Z\|X)$, variational inference proposes a variational distribution over the latent variables, paramatrized by $\phi$. The goal is to make this distribution as close to the true posterior $p(Z\|X)$ as possible.

$$ q(Z | X; \phi) $$

# The "Closeness" of Distributions
In order to find a distribution that is close to $p(Z\|X)$, we need to define what we mean by close. The Kullback-Leibler (KL) Divergence is an information theoretic measure of how well one distribution approximates another. It's usually written, for continuous distributions, as

$$ D_{KL}( P || Q) = \int P(x) \log \frac{P(x)}{Q(x)} $$

where $P$ is the true distribution and $Q$ is the approximate. Note that it is not symmetric: $D_{KL}(P \|\| Q) \ne D_{KL}(Q \|\| P)$. Rearranging this gives us some other perspectives:

$$\begin{align}
D_{KL}( P || Q) &= \mathbb{E}_{P} [ \log \frac{P(x)}{Q(x)} ] \\
 &= -\mathbb{E}_{P} [ \log Q ] + \mathbb{E}_{P} [ \log P ] \\
 &= H(P,Q) - H(P)
\end{align}$$

- $H(P)$ is the entropy of $P$. It represents the uncertainty in $P$, and is the average number of bits needed to communicate a symbol drawn from the distribution. 

- $H(P,Q)$ is the cross-entropy of $Q$ relative to $P$. It represents the average number of bits needed to communicate a symbol drawn from $P$ when it is encoded with respect to $Q$. 

Together, the above equation shows that $D_{KL}(P \|\| Q)$ is the average number of *additional bits* needed communicate a symbol drawn from $P$ when it is encoded with respect to $Q$.

# An Optimization... and a little ELBO grease
Putting the pieces together: Given observations $x$, we'd like to know the (intractable) posterior distribution $p(z \| x)$. Instead, we have chosen a family of tractable distributions $Q$, and we want to find the distribution $q* \in Q$ that best approximates $P(Z \| X)$, perhaps by minimizing the KL divergence:


$$ q* = \arg \min_{q \in q(Z; \phi)} D_{KL}( p(Z | X) || q(Z; \phi))$$

Unfortunately, there are a few hurdles ahead. 

First, $D_{KL}( p(Z\|X) \|\| q(Z; \phi))$ still requires us to work with the intractable posterior $p(Z\|X)$. The trick here is to minimize the *Reverse* KL divergence, $D_{KL}(Q \|\| P)$ instead. 

$$ q* = \arg \min_{q \in q(Z; \phi)} D_{KL}( q(Z; \phi) || p(Z|X) )$$


This won't give us the same optima, but we will still get something that is "close" to $p(Z\|X)$ in a meaningful sense[1].

$$ D_{KL}( q(Z; \phi) || p(Z|X) ) = ...$$


# References and Further Reading

1.  [An Introduction to Variational Inference](https://arxiv.org/pdf/2108.13083)
1. [Chapter 13: Approximate Inference, *Deep Learning*](https://www.deeplearningbook.org/contents/inference.html)
1.  [Autoencoding Variational Bayes](https://arxiv.org/pdf/1312.6114)





